{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Machine Learning I: WS 14/15                        ---- homework by Tom Nick and Niklas Gebauer</h1>\n",
    "\n",
    "<h3>Introduction to Ipython Notebooks</h3>\n",
    "\n",
    "Please consult https://github.com/ipython/ipython/tree/master/examples/notebooks#a-collection-of-notebooks-for-using-ipython-effectively for use of ipython notebooks.\n",
    "\n",
    "http://nbviewer.ipython.org/urls/raw.github.com/jrjohansson/scientific-python-lectures/master/Lecture-4-Matplotlib.ipynb provides great examples of plotting within ipynb\n",
    "\n",
    "Make sure you execute (shift + enter) all necessary code blocks before using them\n",
    "\n",
    "Please add titles to your plots and set the corresponding label to every axis. An example you can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x72d77b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run this first if you want to plot the example yourself\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "\n",
    "# adjust it if you want to see the effects\n",
    "x = np.linspace(0,2)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "for ax in axes:\n",
    "    ax.plot(x, x**2, label=r\"$f(x) = x^2$\")\n",
    "    ax.plot(x, x**0.5, label=r\"$f(x) = \\sqrt{x}$\")\n",
    "    ax.set_xlabel(r'$x$', fontsize=18)\n",
    "    ax.set_ylabel(r'$y$', fontsize=18)\n",
    "    ax.set_title('title') # ALWAYS set a title\n",
    "    ax.legend(loc=2) # Add a legend if necessary\n",
    "fig.tight_layout() # Make sure the figures don't overlap\n",
    "\n",
    "# Ignore the warning, as using axes in this fashion will make plotting significantly easier\n",
    "\n",
    "#In part 2 also consider creating a figure with a specific number of subplots. We looked at i%4.\n",
    "\n",
    "#Ignore the warning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exercise Sheet 1: Bayesian Decision Theory </h3>\n",
    "\n",
    "In this programming assignment we will use Bayes' rule to build a simple junk-mail filter using data avaialbe at http://www.aueb.gr/users/ion/data/enron-spam/.\n",
    "\n",
    "The classifier distinguishes between two classes:\n",
    "\n",
    "* **x = 1 for spam messages **\n",
    "* **x = 0 for ham ( non-spam ) messages **\n",
    "\n",
    "The messages are analyzed by checking for containment of certain words shown to be highly associated with a specific type of message.\n",
    "\n",
    "* Bank, transfer, buy, viagra... for spam messages\n",
    "* Paper, conference, proposal, experiment... for ham messages, as the data was mostly gathered from emails of researchers\n",
    "\n",
    "The classifier determines the probability for each class **assuming independence between occurences of known keywords**:\n",
    "\n",
    "$P(x=i|message) = \\prod_{word \\in message} p(x=i|word)$\n",
    "\n",
    "and using Bayes' rule:\n",
    "\n",
    "$p(x=i|word) = \\frac{p(word|x=i)p(x=i)}{p(word|x=1)p(x=1) + p(word|x=0)p(x=0)}$\n",
    "\n",
    "The message is classified as spam afterwards based on a threshold **T**:\n",
    "\n",
    "$p(x=1|message) > T * p(x=0|message)$\n",
    "\n",
    "As we are only interested in the ratio and not the values of the probabilities themselves, we can also drop the denominator to get\n",
    "\n",
    "$p'(x=i|word) = p(word|x=i)p(x=i)$.\n",
    "\n",
    "<h3>Part I: Calculating the ratio (10P) </h3>\n",
    "\n",
    "Finish the code segment bellow to compute the ratios for the provided data, given the training values (which contain p(word| x=1) and p(word| x=0) as well as the columns which will be used (i.e. only the given words are examined, not all of them). The priors $p(spam)$ and $p(ham)$ are provided \n",
    "\n",
    "Make sure to account for cases where the number of columns is large and we might run into numerical errors when nearing zero. For example, with 40 columns used and most factors smaller than 0.1, we will likely go well bellow 1e-40 when computing the scores. As we are only interested in the ratio, we can freely multiply **both values** with a constant when we wish to.\n",
    "\n",
    "The data is divided the following way:\n",
    "\n",
    "* trainingSpam and trainingHam are arrays containing the estimates for p(word|x=1) and p(word|x=0). They are arrays of len 600, but only the first 50 fields are relevant\n",
    "* testData is a matrix of shape 400 (number points) x 50(number words). testData[i,j]=1 if message i contains the word j\n",
    "* testLabels is an array containing the labels for each of the test messages\n",
    "* validation data and labels have the same description as the test data. They are used for tuning the model (selecting the paramater T, examining the ROC curve...), while the test data is used to check the final result quality on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '1training_spam.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-548a60bcfb47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m#Run the following to extract data used for training and testing purposes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainingSpam\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'1training_spam.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrainingHam\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'1training_ham.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtestData\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'1testData.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtestLabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'1testLabels.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '1training_spam.npy'"
     ]
    }
   ],
   "source": [
    "#Run the following to extract data used for training and testing purposes\n",
    "trainingSpam=numpy.load('1training_spam.npy')\n",
    "trainingHam=numpy.load('1training_ham.npy')\n",
    "testData=numpy.load('1testData.npy')\n",
    "testLabels=numpy.load('1testLabels.npy')\n",
    "validationLabels=numpy.load('1validationLabels.npy')\n",
    "validationData=numpy.load('1validationData.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_ratio(trainingHam, trainingSpam,data, columns):\n",
    "    \"\"\"\n",
    "    Classifies the testData using the specified columns with the given threshold T\n",
    "    \n",
    "    trainingHam - Contains the estimated probabilities p(word|ham) for each word. \n",
    "                  Shape num_features x 1\n",
    "    trainingSpam - Contains the estimated probabilities p(word|spam) for each word. \n",
    "                   Shape num_features x 1\n",
    "    data - The data which will be classified. Shape num_test_messages x num_features\n",
    "    columns -   List (or numpy array) containing the columns which are to be used. \n",
    "                For example. if it contains [1,14,15] the scores are to be computed \n",
    "                by using the values for those 3 words only (i.e. disregarding all \n",
    "                other words).\n",
    "    \"\"\"\n",
    "    \n",
    "    prior_spam = 0.6\n",
    "    prior_ham = 0.4\n",
    "    \n",
    "    # getting the relevant columns (words) of the likelihoods\n",
    "    spam = trainingSpam[columns]\n",
    "    ham = trainingHam[columns]\n",
    "    \n",
    "    # getting the relevant columns (words) of the data\n",
    "    data = data[:,columns]\n",
    "    #print data[100:110]\n",
    "    \n",
    "    # compute the posterior for each word (without denominator)\n",
    "    #spam = spam*prior_spam\n",
    "    #ham = ham*prior_ham\n",
    "    #print ham\n",
    "    #print spam\n",
    "    \n",
    "    # compute posterior for all mesages\n",
    "    dataSpam = data*spam\n",
    "    dataHam = data*ham\n",
    "    dataSpam *= 100 #prevent from under flow\n",
    "    dataHam *= 100\n",
    "    dataSpam[dataSpam==0] = 1.0 # set columns of words which aren't in the message to 1 so that we can take the product\n",
    "    dataHam[dataHam==0] = 1.0\n",
    "    spam_factor = np.prod(dataSpam, axis=1, keepdims=True) # compute the product of all word posteriors\n",
    "    ham_factor = np.prod(dataHam, axis=1, keepdims=True)   # in order to obtain the message's posterior\n",
    "    #print spam_factor[8]\n",
    "    #print dataSpam[100:110]\n",
    "    \n",
    "    #spam_factor = numpy.ones((data.shape[0],1))\n",
    "    #ham_factor = numpy.ones((data.shape[0],1))\n",
    "   \n",
    "    spam_factor*=prior_spam #include the priors\n",
    "    ham_factor*=prior_ham #include the priors\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Make sure we don't get enormous ratios\n",
    "    #ham_factor += (0.0001*spam_factor)\n",
    "    #spam_factor *=1.0001\n",
    "    \n",
    "    ratio = spam_factor/(ham_factor)\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_ratio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-572c4e2c3fd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# You can use this for debugging purposes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m tmp = compute_ratio(trainingHam,trainingSpam,validationData,\n\u001b[0m\u001b[1;32m      4\u001b[0m                     [1,2,3,4,5,6,7,8,9,10])\n\u001b[1;32m      5\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m110\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compute_ratio' is not defined"
     ]
    }
   ],
   "source": [
    "# You can use this for debugging purposes\n",
    "\n",
    "tmp = compute_ratio(trainingHam,trainingSpam,validationData,\n",
    "                    [1,2,3,4,5,6,7,8,9,10])\n",
    "a = tmp[100:110]\n",
    "sample_ratios = numpy.load('Sample_ratios.npy')\n",
    "#print a\n",
    "#print sample_ratios\n",
    "for i in range(10):\n",
    "    assert(a[i]>(sample_ratios[i]-0.01) and \n",
    "           a[i]<(sample_ratios[i]+0.01))\n",
    "print \"Results seem to match\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Part II: Choosing parameters (20P) </h3>\n",
    "We need to determine a set of columns which produces good results **and a threshold parameter T**. However as there are $2^{num features}$ possible combinations for the column set, we can't implement a brute force solution. \n",
    "\n",
    "One way to limit our search space is to look for a solution iteratively. We will limit our search space by iteratively searching for the best column to add to our current set, starting with an empty set of columns. This way we have $O(n*k)$ complexity, where k is the upper bound for the number of features to consider, rather than exponential complexity. We need to examine the effects of adding a column and find a threshold value $T$ which performs best. **The validation set is used for this**. Training then looks like this:\n",
    "\n",
    "* Start with an empty set of columns\n",
    "* Iterate until we reach the desired number k, in this case 32\n",
    "    * Iterate over all columns not in the set\n",
    "        * We need to check the values for **a wide range of values for the parameter T**. \n",
    "        * The optimal value for T as well as the optimal column added (j) need to be recorded\n",
    "        * To visualize the effects of the parameter T we record the true-positive rates and false-positive rates necessary to visualize the ROC curve (see: http://en.wikipedia.org/wiki/Receiver_operating_characteristic )\n",
    "    * We visualize the ROC curve for the new set of columns. So if we found that coulmn 3 was the best addition, we visualize result quality for columns $\\cup$ {3}. The ROC curve shows values we observed for various T\n",
    "    * To check quality, we also include the F1 score on the test data for the chosen optimal value of T (so only the value that performed best on the validation data, not a range). This is the final measure of quality.\n",
    "\n",
    "An example of our results is included bellow. There are 4 subplots per figure, the figure includes a line x=x (red) and the roc curve(blue). The parameters shown are:\n",
    "\n",
    "* F1 score on validation data\n",
    "* F1 score on test data\n",
    "* The number of columns used (i)\n",
    "\n",
    "Run tests using the full validation set, as well portions of it. Make sure you select a segment which contains both types of messages. The first 200 are spam and the following 200 aren't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_experiment(trainingHam,trainingSpam,validationData,\n",
    "                   validationLabels,testData,testLabels):\n",
    "    T = np.linspace(0.05,10,num=100)\n",
    "    mask = np.ones((validationData.shape[0],len(T)))\n",
    "    columns = []\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,40))\n",
    "    \n",
    "    # get number of positives and negatives in our test and validation data\n",
    "    val_positives = np.sum(validationLabels)\n",
    "    val_negatives = validationLabels.shape[0] - val_positives\n",
    "    test_positives = np.sum(testLabels)\n",
    "    test_negatives = testLabels.shape[0] - test_positives\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_T = 0\n",
    "    best_col = 0\n",
    "    best_results = []\n",
    "    \n",
    "    \n",
    "    for i in range(1,33): #You can make this smaller during testing\n",
    "        #Find optimal column and its T\n",
    "        for j in range(50):\n",
    "            if not (j in columns):\n",
    "                ratios = compute_ratio(trainingHam,trainingSpam,validationData,columns+[j])\n",
    "                rat_mat = ratios * mask\n",
    "                results = rat_mat > T                       #check where ratio is bigger than threshold\n",
    "                #print results[[0,399],20]\n",
    "                label_comp = results == validationLabels    #check where labels equal the result\n",
    "                accuracies = np.sum(label_comp, axis = 0)   #count the number of correct classifications\n",
    "                #print accuracies[0:50]\n",
    "                current_acc = np.amax(accuracies)           #find the greatest accuracy\n",
    "                indices = np.argwhere(accuracies==current_acc)  #find indices of the greatest accuracy\n",
    "                current_ind = indices[len(indices)/2]       #take an index close to the middle of possible indices\n",
    "                current_T = T[current_ind]                  # get the corresponding value for T\n",
    "                if current_acc > best_acc:                  #keeping track of the best found column so far\n",
    "                    best_col = j\n",
    "                    best_acc = current_acc\n",
    "                    best_T = current_T\n",
    "                    best_results = results\n",
    "                    best_ind = current_ind\n",
    "                    \n",
    "                    \n",
    "        #Add the column to the set\n",
    "        columns = columns + [best_col]\n",
    "        best_acc = 0\n",
    "        \n",
    "        \n",
    "        #Visualize ROC curve with the two F1 scores\n",
    "        \n",
    "        #initialize plot and y=x curve\n",
    "        plt.subplot(8,4,i)\n",
    "        plt.plot(np.linspace(0.0,1.0,num=11),np.linspace(0.0,1.0,num=11), color='red', marker=None)\n",
    "        \n",
    "        # calculate true positive rates and false positive rates for all T's\n",
    "        all_tp = np.sum(np.logical_and((best_results == True), (validationLabels == True)),axis=0)\n",
    "        all_fp = np.sum(np.logical_and((best_results == True), (validationLabels == False)),axis=0)\n",
    "        tp_rate = all_tp/val_positives\n",
    "        fp_rate = all_fp/val_negatives\n",
    "        \n",
    "        #plot rates\n",
    "        plt.plot(fp_rate,tp_rate, color='blue', marker='x')\n",
    "        \n",
    "        #calculate F1 score on validation set\n",
    "        best_fn = np.sum(np.logical_and((best_results[:,best_ind] == False), (validationLabels == True)))\n",
    "        best_tp = all_tp[best_ind]\n",
    "        best_fp = all_fp[best_ind]\n",
    "        F1_val = np.around(2*best_tp/float((2*best_tp+best_fp+best_fn)),2)\n",
    "        #print F1_val\n",
    "        \n",
    "        #calculate F1 score on test set\n",
    "        test_ratios = compute_ratio(trainingHam,trainingSpam,testData,columns)\n",
    "        test_results = test_ratios > current_T\n",
    "        test_fn = np.sum(np.logical_and((test_results == False), (testLabels == True)))\n",
    "        test_tp = np.sum(np.logical_and((test_results == True), (testLabels == True)))\n",
    "        test_fp = np.sum(np.logical_and((test_results == True), (testLabels == False)))\n",
    "        F1_test = np.around(2*test_tp/float((2*test_tp+test_fp+test_fn)),2)\n",
    "        #print F1_test\n",
    "        \n",
    "        #add title with F1 scores\n",
    "        plt.title('F1 for val = ' + str(F1_val[0]) + ', F1 for test = ' + str(F1_test) + ', i = ' + str(i))\n",
    "\n",
    "        \n",
    "    #fig.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainingHam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b646ad0251db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingHam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainingSpam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidationData\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidationLabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtestData\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtestLabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainingHam' is not defined"
     ]
    }
   ],
   "source": [
    "run_experiment(trainingHam,trainingSpam,validationData,validationLabels,testData,testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainingHam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-615fba873f9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingHam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainingSpam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidationData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m180\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m220\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidationLabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m180\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m220\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtestData\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtestLabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainingHam' is not defined"
     ]
    }
   ],
   "source": [
    "run_experiment(trainingHam,trainingSpam,validationData[180:220,:],validationLabels[180:220],testData,testLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Part III: Analysis (10P) </h3>\n",
    "\n",
    "*Will our iterative approach for finding the solution always find an optimal solution? Explain your answer.*\n",
    "\n",
    "**No, it will not always find an optimal solution. We limit ourselves by irreversibly choosing one column, because in the following steps we will just be able to judge the performance based on a combination of a new column and our already chosen columns. But there might for example exist a better solution, that doesn't contain the column that we have chosen in our very first iteration. Our approach will not be able to inspect those combinations not containing the first chosen column.**\n",
    "\n",
    "*Explain the need for separate validation and test data when conducting tests*\n",
    "\n",
    "**It's important to choose parameters on a different set than the one you test your final performance on, because while validation you can easily overfit or underfit the validation set. If you overfit, the classifier will work perfectly fine on the validation set but poorly generalize and thus be useless. If you underfit the boundary will be too simple to classify properly and thus work bad on either the validation and the test set. So a separate set for validation and test data is needed to first learn the parameters and then check whether the parameters learned yield a useful generalization.**\n",
    "\n",
    "\n",
    "\n",
    "*What kind of performance w.r.t false-positives and false-negatives is favorable for a spam-filter? How would you adjust your code to reflect this type of behavior. Give an example of the opposite type of behaviour*\n",
    "\n",
    "**It's clearly favorable to have less false-positives (and so probably more false-negatives) than the other way around. The reason is that the user usually doesn't want to have important messages (ham, for example for appointments etc.) filtered out by the spam filter. It's rather acceptable to handpick some spam messages that are not caught by the filter than to miss an important message because it's in the spam directory.**\n",
    "\n",
    "**There are many ways to reflect this type of behaviour. The easiest would be to change the priors in favour of ham, so that the classifier tends to classify as ham since it expects more ham than spam messages. We could also define a loss-function that does the job by weighting a ham message classified as spam as a worse error than classifying spam as ham. Another way is to adjust the threshold. If we raise the threshold we will just classify those messages as spam, that have a very high ratio, meaning that either the spam factor is really high or the ham factor is really low. If we would lower the threshold we would have the different type of behaviour: the classifier would classify many messages as spam, although the spam factor is not extremly large or the ham factor is not extremly small. So the user would rarely get any spam messages but also lose a lot of ham messages.**\n",
    "\n",
    "**A last approach of reflecting the desired behaviour would be a different kind of measurement as 'best column' during the validation. In our approach we took the column with the best overall accuracy (the least wrongly classified messages). One could try to look for columns with a low false-postive rate (maybe defining an upper bound like 1 percent) and search among these columns fo the one that still classifies the most spam mails correctly as spam (true-positive rate)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
