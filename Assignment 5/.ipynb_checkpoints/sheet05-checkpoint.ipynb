{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "name": "",
  "signature": "sha256:5178a97ce6a5477f3862e356067378cae7229e752b639e8c273511f2f1e81f9c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Fisher Linear Discriminant\n",
      "\n",
      "In this exercise, you will apply Fisher Linear Discriminant as described in Chapter 3.8.2 of Duda et al. on the UCI Abalone dataset. A description of the dataset is given at the page https://archive.ics.uci.edu/ml/datasets/Abalone. The following two methods are provided for your convenience: \n",
      "\n",
      "\n",
      "* **`utils.Abalone.__init__(self)`** reads the Abalone data and instantiates three data matrices of size (1528, 7), (1307, 7), and (1342, 7) corresponding to the three classes in the dataset: *male (M)*, *female (F)*, and *infant (I)*.\n",
      "\n",
      "\n",
      "* **`utils.Abalone.plot(self,w)`** produces a histogram of the data when projected onto a vector `w`, and where each class is shown in a different color.\n",
      "\n",
      "\n",
      "Sample code that makes use of these two methods is given below. It loads the data, looks at the shape of instantiated matrices, and plots various projections of the data: (1) projection on the first dimension of the data, and (2) projection on a random direction."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import utils,numpy\n",
      "\n",
      "# Load the data\n",
      "abalone = utils.Abalone()\n",
      "\n",
      "# Print dataset size for each class\n",
      "print(abalone.M.shape,abalone.F.shape, abalone.I.shape)\n",
      "\n",
      "# Project data on the first dimension\n",
      "w1 = numpy.array([1,0,0,0,0,0,0])\n",
      "abalone.plot(w1,'projection on the first dimension')\n",
      "\n",
      "# Project data on a random direction\n",
      "w2 = numpy.random.normal(0,1,[7])\n",
      "w2 /= (w2**2).sum()**.5\n",
      "abalone.plot(w2,'projection on a random direction')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Implementation (30 P)\n",
      "\n",
      "* **Create a method `w = fisher(X1,X2)` that takes as input the data for two classes and returns the Fisher linear discriminant.**\n",
      "\n",
      "\n",
      "* **Create a method `J(X1,X2,w)` that evaluates the objective defined in Equation 96 of Duda et al. for an arbitrary projection vector `w`.**\n",
      "\n",
      "\n",
      "* **Create a method `z = phi(X)` that returns a quadratic expansion for each data point `x` in the dataset. Such expansion consists of the vector `x` itself, to which we concatenate the vector of all pairwise products between elements of `x`.** In other words, letting $x = (x_1,\\dots,x_d)$ denote the $d$-dimensional data point, the quadratic expansion for this data point is a $d \\cdot (d+3)/2$ dimensional vector given by $\\phi(x) = (x_i)_{1 \\leq i \\leq d} \\cup (x_i x_j)_{1 \\leq i \\leq j \\leq d}$. For example, the quadratic expansion for $d=2$ is $(x_1,x_2,x_1^2,x_2^2,x_1 x_2)$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##### YOUR CODE HERE\n",
      "\n",
      "#####"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Analysis (20 P)\n",
      "\n",
      "* **Print the value of `J(w)` for each discriminated pair of classes (M/F, M/I, F/I), and for several values of `w`:**\n",
      "\n",
      "  * `w` is a vector that projects the data on the each dimension of the data.\n",
      "  * `w` is the difference between the mean vectors of the two classes.\n",
      "  * `w` is the difference between the mean vectors of the two classes (after quadratic expansion of the data).\n",
      "  * `w` is the Fisher linear discriminant.\n",
      "  * `w` is the Fisher linear discriminant (after quadratic expansion of the data).\n",
      "\n",
      "\n",
      "* **For the simple Fisher linear discriminant, plot a histogram of the projected data for each discriminated pair of classes using the function `utils.Abalone.plot()`.**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##### REPLACE BY YOUR CODE\n",
      "%matplotlib inline\n",
      "import solutions\n",
      "solutions.analysis()\n",
      "#####"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}